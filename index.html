<!DOCTYPE HTML>
<!--
	Telephasic by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>PongBot</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="homepage is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header-wrapper">
					<div id="header" class="container">

						<!-- Logo -->
							<h1 id="logo"><a href="index.html">PongBot</a></h1>

						<!-- Nav -->
							<nav id="nav">
								<ul>
									<li><a href="navigation.html">Navigation</a></li>
									<li><a href="acoustics.html">Acoustics</a></li>
									<li class="break"><a href="state-machine.html">FSM</a></li>
									<li><a href="obs-avoidance.html">Obstacle Avoidance</a></li>
								</ul>
							</nav>

					</div>

					<!-- Hero -->
						<section id="hero" class="container">
							<header>
								<h2>PongBot uses sound to locate and travel to objects of interest in an obstacle-ridden room.
								</h2>
							</header>
							<p>Programmed by Nir Levin, Kyle Tucker, & Jay Garg.</p>
							<h3><a href="https://github.com/nLevin13/PingPongFinder">The PongBot Repository</a></h3>
						</section>

				</div>
			<!-- Main -->
				<div class="wrapper">
					<div class="container" id="main">
						<article id="content">
							<h2 class="feature center">Our Goal</h2>
							<br>
							<p>To build a system that locates an indoor audio source and drives to it for retrieval. The concept of locating and retrieving items based on wave propagations can be a base template for products in many different fields and applications. Inspired by the idea to automate ping pong ball retrieval. Our main problems to solve are:</p>
							<ul>
								<li>Triangulation of sound wave emitting object</li>
								<li>Path finding to the source location</li>
								<li>Stable driving towards the source location</li>
								<li>On-the-fly obstacle avoidance</li>
							</ul>
							<br>
							<hr>
							<br>
							<h2 class="feature center">Design & Implementation</h2>
							<br>
							<ul class="feature center">
								<li>Our system simulates and listens for an audio source which it then locates, detailed on <a href="acoustics.html">Acoustics</a></li>
								<li>PongBot uses a path planning algorithm and a PID controller to drive to it's destination, found on <a href="navigation.html">Navigation</a></li>
								<li>While driving along it's path, it makes adjustments for any unexpected obstructions by implementing <a href="obs-avoidance.html">Obstacle Avoidance</a></li>
								<li>The communication between our multiple processes is integrated with a <a href="acoustics.html">Finite State Machine</a></li>
							</ul>
							<br>
							<hr>
							<br>
							<h2 class="feature center">PongBot Demo</h2>
							<br>
							<center><iframe width="560" height="315" src="https://www.youtube.com/embed/IoScVM8afQg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></center>
							<br>
							<hr>
							<br>
							<h2 class = "feature center">Results</h2>
							<br>
							<p>All parts of our design work separately and most of our processes are integrated together. For example, the acoustics system locates and provides its predicted location to the robot. The robot waits for a signal from the acoustics system, then autonomously calculates a path and drives towards the goal. This is all handled in the background by the FSM.</p>
							<p>The one portion which had required a lot more involvement than we originally thought was the obstacle detection and avoidance, which isn't fully integrated into our final product. However, it does work separately, as shown <a href="obs-avoidance.html"></a></p>
							<p>We discuss challenges and difficulties for each portion of the implementation individually, within their respective <a href="#">subpages</a>.</p>
							<br>
							<hr>
							<br>
							<h2 class="feature center">Impact</h2>
							<br>
							<p>The reason this project was so interesting was that this concept of locating and retrieving items based on the waves they emit can be applied throughout many different areas of study. Many of these applications have already been created when the waves being emitted are electromagnetic, but we haven't seen many products involving tracking based on audio signals. Some fields where this can be useful include but are not limited to:</p>
							<ul>
								<li>Indoor search and rescue</li>
								<li>Bringing items for disabled individuals</li>
								<li>Military audio tracking</li>
								<li>3D target tracking</li>
								<li>Recovery of payload which emits any propagating wave</li>
							</ul>
							<p>We can see that there are many cases where a PongBot style system may be useful. However, they do come with some significant social impacts which we almost overlooked. Using this application for something like detecting fired weapons in a military setting can be very useful for whichever side has access to the technology. While using it in the civilian side to prevent attacks may also be extremely useful, this also creates the age old dilemma of privacy vs security. Even when using this technology purely for safety, locating someone in a burning building for example, whenever the microphones are on, they will be recording everything, which again leads us back to the possible harm in having a government with access to our conversations. While some of these applications may be a possible source of controversy, the benefits themselves make this idea worth investigating, so long as we proceed with caution.</p>
							<br>
							<hr>
							<br>
							<h2 class="feature center">Our Team</h2>
					<!-- Features 2 -->
				<div class="wrapper">
					<section class="container">
						<div class="row features">
							<section class="col-4 col-12-narrower feature">
								<div class="image-wrapper first">
									<a href="#" class="image featured"><img src="images/nir.png" alt="" /></a>
								</div>
								<p>Nir Levin is a third-year EECS student from San Diego, California. He specializes and is interested in pursuing computer vision, especially in autonomous underwater vehicles. He enjoys some casual mountain biking and hiking in his free time. He focused on PongBot's navigation ability, including path finding and path tracking.
								<br>
								<br>
								nirlevin@berkeley.edu</p>
								<ul class="actions major">
									<li><a href="https://www.linkedin.com/in/nir-levin-cal/" target="_blank" class="button" style="padding:24px"><img src="images/linkedin-logo.png" style="width:50px;height:50px;"></a></li>
								</ul>
								<ul class="actions major">
									<li><a href="https://github.com/nLevin13" target="_blank" class="button" style="padding:17px"><img src="images/github-logo.png" style="width:60px;height:60px;"></a></li>
								</ul>
							</section>
							<section class="col-4 col-12-narrower feature">
								<div class="image-wrapper">
									<a href="#" class="image featured"><img src="images/kyle.png" alt="" /></a>
								</div>
                                <p>Kyle Tucker is a fourth-year EECS student from Chula Vista, California. He has experience with autonomous robotic vehicles, and is deeply passionate about the game Super Smash Bros Melee (2001). He focused on the FSM and Obstacle Avoidance nodes within PongBot.
								<br>
								<br>
								<br>
								kyletucker@berkeley.edu</p>
								<ul class="actions major">
									<li><a href="https://www.linkedin.com/in/kylemtucker/" target="_blank" class="button" style="padding:24px"><img src="images/linkedin-logo.png" style="width:50px;height:50px;"></a></li>
								</ul>
								<ul class="actions major">
									<li><a href="https://github.com/kylemtucker" target="_blank" class="button" style="padding:17px"><img src="images/github-logo.png" style="width:60px;height:60px;"></a></li>
								</ul>
							</section>
							<section class="col-4 col-12-narrower feature">
								<div class="image-wrapper">
									<a href="#" class="image featured"><img src="images/jay.jpg" alt="" /></a>
								</div>
								<p>Jay Garg is a fourth year Astrophysics student <br> with a minor in Mechanical Engineering <br>from Los Angeles, California. <br> Aside from job hunting, he enjoys going outdoors and playing guitar. He focused on the acoustics simulations and audio triangulation functionality within the PongBot System.
								<br>
								<br>
								jgarg20@berkeley.edu</p>
								<ul class="actions major">
									<li><a href="https://www.linkedin.com/in/jay-garg/" target="_blank" class="button" style="padding:24px"><img src="images/linkedin-logo.png" style="width:50px;height:50px;"></a></li>
								</ul>
								<ul class="actions major">
									<li><a href="https://github.com/JayRGarg" target="_blank" class="button" style="padding:17px"><img src="images/github-logo.png" style="width:60px;height:60px;"></a></li>
								</ul>
							</section>
						</div>
					</section>
				</div>
						</article>
					</div>
				</div>
		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
